<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/toxicity"></script>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
  <title>Toxicity</title>
  <script>


  </script>
  <style>
    body{
      width: 100vw; height: 100vh;
      background: rgb(143,200,255);
      background: radial-gradient(circle, rgba(143,200,255,1) 0%, rgba(78,168,255,1) 100%);
      background-repeat: no-repeat;      
    }
  </style>
</head>

<body>
  <div id="container" class="container mt-5" >
    <div class="row text-center font-weight-bold mb-3 text-dark">      
      <h2>Toxicity with TFjs</h2>
    </div>
    <div id="input-wrap" class="row">
      <div class="col text-center fs-3 mx-auto">
        <input type="text" class="w-50 rounded border-light"
          placeholder="Sentence here"
          value="this sucks"
          onChange="detect_toxicity(this.value)"/>
      </div>
    </div>    
    <div class="row">       
      <div id="response-spinner" class="visually-hidden col text-center mx-auto mt-5">        
        <div class="spinner-border mx-auto text-dark">
          <span class="visually-hidden">Loading</span>
        </div>
      </div>
      <div id="response-wrap" class="col fs-2 text-center mx-auto mt-5">        
        <span id="pred-label"></span>
        <span id="pred-prob"></span>
      </div>
    </div>
  </div>
  <script>
    // Code adapted from: https://github.com/tensorflow/tfjs-models/tree/master/toxicity

    // The minimum prediction confidence.
    let tox_model = {};

    // Load the model. Users optionally pass in a threshold and an array of
    // labels to include.
    function load_model() {
      toxicity
        .load()
        .then(model => tox_model = model);
    }

    function detect_toxicity(sentence) {                  
      document.querySelector("#response-wrap").classList.toggle("visually-hidden");
      document.querySelector("#response-spinner").classList.toggle("visually-hidden");

      tox_model.classify([sentence]).then(predictions => {
        // `predictions` is an array of objects, one for each prediction head,
        // that contains the raw probabilities for each input along with the
        // final prediction in `match` (either `true` or `false`).
        // If neither prediction exceeds the threshold, `match` is `null`.
        console.log(predictions);
        
        const maxPred = predictions
          .sort((a, b) => {
            const getProb = (x) => {
              return x.results[0].probabilities[1];
            }
            return getProb(b) - getProb(a);
          });
        console.log(maxPred[0].label);
        document.querySelector("#response-spinner").classList.toggle("visually-hidden");
        document.querySelector("#response-wrap").classList.toggle("visually-hidden");
        document.querySelector("#pred-label").textContent = maxPred[0].label;
        const prob = maxPred[0].results[0].probabilities[1];
        document.querySelector("#pred-prob").textContent = Math.round(prob*100) + "%"

      })
    }

    load_model();
  </script>
</body>

</html>